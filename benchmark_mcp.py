import asyncio
import time
import os
import sys
import json
import logging
import statistics
import io
from datetime import datetime

# å¼ºåˆ¶ stdout/stderr ä½¿ç”¨ UTF-8 ç¼–ç 
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# åˆ‡æ¢å·¥ä½œç›®å½•åˆ° client/mcp-clientï¼Œç¡®ä¿ mcp_servers.json ä¸­çš„ç›¸å¯¹è·¯å¾„æ­£ç¡®
PROJECT_ROOT = os.getcwd()
CLIENT_DIR = os.path.join(PROJECT_ROOT, 'client', 'mcp-client')
if os.path.exists(CLIENT_DIR):
    os.chdir(CLIENT_DIR)
    print(f"ğŸ“‚ å·²åˆ‡æ¢å·¥ä½œç›®å½•è‡³: {os.getcwd()}")

# æ·»åŠ  client ç›®å½•åˆ°è·¯å¾„ (ç°åœ¨æ˜¯å½“å‰ç›®å½•)
sys.path.insert(0, os.getcwd())

try:
    from client import MCPClient
except ImportError:
    print("âŒ æ— æ³•å¯¼å…¥ MCPClient")
    sys.exit(1)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# æ·»åŠ æ–‡ä»¶æ—¥å¿—å¤„ç†å™¨ï¼Œç¡®ä¿è¾“å‡º UTF-8 ç¼–ç çš„æŠ¥å‘Š
file_handler = logging.FileHandler('benchmark_report.utf8.txt', mode='w', encoding='utf-8')
file_handler.setLevel(logging.INFO)
file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
logger.addHandler(file_handler)
# åŒæ—¶å°† print è¾“å‡ºä¹Ÿé‡å®šå‘åˆ°æ–‡ä»¶ï¼ˆæˆ–è€…ç”¨ logger æ›¿ä»£ printï¼‰
class LoggerWriter:
    def __init__(self, logger, level=logging.INFO):
        self.logger = logger
        self.level = level
        self.buffer = ""

    def write(self, message):
        if message.strip():
            self.logger.log(self.level, message.strip())

    def flush(self):
        pass

# æ›¿æ¢ sys.stdout å¯èƒ½ä¼šå½±å“ subprocessï¼Œæ‰€ä»¥æˆ‘ä»¬åªåœ¨ generate_report é‡Œç”¨ logger
# æˆ–è€…ç®€å•ç‚¹ï¼ŒæŠŠæ‰€æœ‰ print æ¢æˆ logger.info

# æµ‹è¯•é…ç½®
CONFIG_PATH = 'mcp_servers.json' # ç°åœ¨å¯ä»¥ç›´æ¥ç”¨ç›¸å¯¹è·¯å¾„
CONCURRENT_REQUESTS = 5  # å¹¶å‘è¯·æ±‚æ•°
TEST_ROUNDS = 3          # æµ‹è¯•è½®æ•°

class MCPBenchmark:
    def __init__(self):
        self.client = MCPClient()
        self.results = {
            "irrigation": {"latency": [], "success": 0, "total": 0},
            "weather": {"latency": [], "success": 0, "total": 0}
        }

    async def setup(self):
        """åˆå§‹åŒ– MCP å®¢æˆ·ç«¯"""
        logger.info("ğŸš€ åˆå§‹åŒ– MCP å®¢æˆ·ç«¯...")
        if not os.path.exists(CONFIG_PATH):
            logger.error(f"é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {CONFIG_PATH}")
            return False
        
        await self.client.load_servers_from_config(CONFIG_PATH)
        await self.client.list_tools()
        return True

    async def call_tool(self, service, tool_name, args):
        """è°ƒç”¨å•ä¸ªå·¥å…·å¹¶è®°å½•è€—æ—¶"""
        start_time = time.perf_counter()
        success = False
        try:
            if service not in self.client.sessions:
                logger.error(f"æœåŠ¡ {service} æœªè¿æ¥")
                return
            
            session = self.client.sessions[service]["session"]
            await asyncio.wait_for(session.call_tool(tool_name, args), timeout=10)
            success = True
        except Exception as e:
            logger.error(f"è°ƒç”¨ {tool_name} å¤±è´¥: {e}")
        finally:
            end_time = time.perf_counter()
            latency = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            self.results[service]["total"] += 1
            if success:
                self.results[service]["success"] += 1
                self.results[service]["latency"].append(latency)
            
            return latency, success

    async def run_concurrent_tests(self, service, tool_name, args):
        """æ‰§è¡Œå¹¶å‘æµ‹è¯•"""
        logger.info(f"ğŸ”¥ å¼€å§‹æµ‹è¯•æœåŠ¡: {service} (å·¥å…·: {tool_name})")
        tasks = []
        for _ in range(CONCURRENT_REQUESTS):
            tasks.append(self.call_tool(service, tool_name, args))
        
        await asyncio.gather(*tasks)

    async def run_benchmark(self):
        """è¿è¡Œå®Œæ•´åŸºå‡†æµ‹è¯•"""
        try:
            if not await self.setup():
                return

            logger.info("="*60)
            logger.info(f"ğŸ“Š MCP å¤šæºæ•°æ®è·å–æ€§èƒ½æµ‹è¯•")
            logger.info(f"å¹¶å‘æ•°: {CONCURRENT_REQUESTS} | è½®æ•°: {TEST_ROUNDS}")
            logger.info("="*60)

            for round in range(1, TEST_ROUNDS + 1):
                logger.info(f"--- ç¬¬ {round} è½®æµ‹è¯• ---")
                
                # 1. æµ‹è¯•ä¼ æ„Ÿå™¨æ•°æ® (Irrigation Service)
                await self.run_concurrent_tests("irrigation", "get_sensor_data", {})
                
                # 2. æµ‹è¯•æ°”è±¡æœåŠ¡ (Weather Service)
                await self.run_concurrent_tests("weather", "get_observe", {"province": "åŒ—äº¬", "city": "åŒ—äº¬"})
                
                # é—´éš”ä¸€ä¸‹ï¼Œé¿å…è¯·æ±‚è¿‡å¿«
                await asyncio.sleep(1)

        except Exception as e:
            logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿæœªæ•è·å¼‚å¸¸: {e}", exc_info=True)
        finally:
            # æ— è®ºå¦‚ä½•éƒ½ç”ŸæˆæŠ¥å‘Š
            self.generate_report()
            # æœ€åå°è¯•æ¸…ç†èµ„æº
            try:
                await self.client.clean()
            except Exception as e:
                logger.error(f"æ¸…ç†èµ„æºæ—¶å‡ºé”™: {e}")

    def generate_report(self):
        """ç”Ÿæˆå¹¶æ‰“å°æµ‹è¯•æŠ¥å‘Š"""
        logger.info("="*60)
        logger.info("ğŸ“ˆ æµ‹è¯•æŠ¥å‘Š")
        logger.info("="*60)
        
        for service, data in self.results.items():
            total = data["total"]
            if total == 0:
                logger.info(f"æœåŠ¡: {service} (æ— æ•°æ®)")
                continue
                
            success_rate = (data["success"] / total) * 100
            latencies = data["latency"]
            
            logger.info(f"ğŸ”¹ æœåŠ¡: {service.upper()}")
            logger.info(f"   - æ€»è¯·æ±‚æ•°: {total}")
            logger.info(f"   - æˆåŠŸç‡:   {success_rate:.1f}%")
            
            if latencies:
                avg_lat = statistics.mean(latencies)
                min_lat = min(latencies)
                max_lat = max(latencies)
                p95_lat = statistics.quantiles(latencies, n=20)[18] if len(latencies) >= 20 else max_lat
                
                logger.info(f"   - å¹³å‡å“åº”: {avg_lat:.2f} ms")
                logger.info(f"   - æœ€å°å“åº”: {min_lat:.2f} ms")
                logger.info(f"   - æœ€å¤§å“åº”: {max_lat:.2f} ms")
                logger.info(f"   - P95 å“åº”: {p95_lat:.2f} ms")
            else:
                logger.info("   - å“åº”æ—¶é—´: N/A (å…¨å¤±è´¥)")

        logger.info("="*60)

if __name__ == "__main__":
    benchmark = MCPBenchmark()
    asyncio.run(benchmark.run_benchmark())