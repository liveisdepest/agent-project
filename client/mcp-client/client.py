import asyncio
import os
import time
import uuid
import re
from urllib.parse import quote_plus, urlparse
from openai import OpenAI
from dotenv import load_dotenv
from contextlib import AsyncExitStack, suppress
from mcp import ClientSession, StdioServerParameters
from mcp.client.sse import sse_client
from mcp.client.stdio import stdio_client
import json
import logging
from prompts import ORCHESTRATOR_PROMPT, PERCEPTION_PROMPT, REASONING_PROMPT, ACTION_PROMPT

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()

# SYSTEM_PROMPT Removed in favor of multi-agent prompts

class MCPClient:
    def __init__(self, connection_timeout: int = 60, max_retries: int = 3, tool_timeout: int = 120):
        """åˆå§‹åŒ– MCP å®¢æˆ·ç«¯"""
        self._server_exit_stacks = {}
        self._server_processes = {}
        self._load_env_variables()

        self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)
        self.sessions = {}
        self.tools_map = {}
        self.conversation_history = []
        
        # çŠ¶æ€ç®¡ç†
        self.pending_decision = None
        
        # è¶…æ—¶å’Œé‡è¯•é…ç½®
        self.connection_timeout = connection_timeout
        self.max_retries = max_retries
        self.tool_timeout = tool_timeout
        
        logger.info(f"âš™ï¸  è¶…æ—¶é…ç½®: è¿æ¥={connection_timeout}s, å·¥å…·è°ƒç”¨={tool_timeout}s, é‡è¯•={max_retries}æ¬¡")

    def _load_env_variables(self):
        """åŠ è½½å¹¶éªŒè¯ç¯å¢ƒå˜é‡"""
        self.api_key = os.getenv("API_KEY")
        self.base_url = os.getenv("BASE_URL")
        self.model = os.getenv("MODEL")
    
        if not self.api_key:
            raise ValueError("æœªæ‰¾åˆ° API KEY. è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½® API_KEY")
        if not self.base_url:
            logger.warning("æœªæ‰¾åˆ° BASE_URLï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼æˆ–å¯èƒ½å¯¼è‡´é”™è¯¯ã€‚è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½® BASE_URL")
        if not self.model:
            logger.warning("æœªæ‰¾åˆ° MODELï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼æˆ–å¯èƒ½å¯¼è‡´é”™è¯¯ã€‚è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½® MODEL")

    async def load_servers_from_config(self, config_filename: str):
        """ä»é…ç½®æ–‡ä»¶åŠ è½½æœåŠ¡å™¨ï¼ˆæ”¯æŒå¤±è´¥è·³è¿‡ï¼‰
        
        Args:
            config_filename: é…ç½®æ–‡ä»¶åï¼Œå°†è‡ªåŠ¨è§£æä¸ºç›¸å¯¹äºè„šæœ¬çš„ç»å¯¹è·¯å¾„
        """
        # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
        base_dir = os.path.dirname(os.path.abspath(__file__))
        config_path = os.path.join(base_dir, config_filename)

        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
        except FileNotFoundError:
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ {config_path} æœªæ‰¾åˆ°")
        except json.JSONDecodeError:
            raise ValueError(f"é…ç½®æ–‡ä»¶ {config_path} æ ¼å¼é”™è¯¯")

        servers = config.get("mcpServers", {})
        successful_connections = 0
        total_servers = len(servers)
        
        logger.info(f"å¼€å§‹è¿æ¥ {total_servers} ä¸ªMCPæœåŠ¡...")
        
        for server_id, server_config in servers.items():
            url = server_config.get("url", None)
            command = server_config.get("command", None)
            args = server_config.get("args", [])
            env_config = server_config.get("env", None)
            cwd = server_config.get("cwd", None)
            timeout = server_config.get("timeout", None)
            max_retries = server_config.get("max_retries", None)
            
            env = self._build_child_env(server_id, env_config)
            
            # å°è¯•è¿æ¥ï¼Œå¤±è´¥åˆ™è·³è¿‡
            print(f"DEBUG: Attempting to connect to {server_id}...")
            if url:
                success = await self.connect_to_sse_server(
                    server_id,
                    url,
                    command=command,
                    args=args,
                    env=env,
                    cwd=cwd,
                    timeout=timeout,
                    max_retries=max_retries,
                )
            else:
                if not command:
                    logger.error(f"âŒ æœåŠ¡ç«¯ {server_id} ç¼ºå°‘ command/url é…ç½®ï¼Œè·³è¿‡")
                    continue
                print(f"DEBUG: Connecting to local server {server_id} with command: {command} {args}")
                success = await self.connect_to_local_server(
                    server_id,
                    command,
                    args,
                    env,
                    cwd=cwd,
                    timeout=timeout,
                    max_retries=max_retries,
                )
            print(f"DEBUG: Connection to {server_id} result: {success}")
            if success:
                successful_connections += 1

        logger.info(f"ğŸ“Š è¿æ¥ç»“æœ: {successful_connections}/{total_servers} ä¸ªæœåŠ¡è¿æ¥æˆåŠŸ")
        
        if successful_connections == 0:
            logger.error("âš ï¸  æ²¡æœ‰ä»»ä½•MCPæœåŠ¡è¿æ¥æˆåŠŸï¼Œè¯·æ£€æŸ¥é…ç½®å’ŒæœåŠ¡çŠ¶æ€")
        elif successful_connections < total_servers:
            logger.warning(f"âš ï¸  éƒ¨åˆ†æœåŠ¡è¿æ¥å¤±è´¥ï¼Œå½“å‰å¯ç”¨æœåŠ¡æ•°: {successful_connections}")

    def _build_child_env(self, server_id: str, env_config: dict | None):
        env = os.environ.copy()
        if env_config:
            env.update(env_config)
        return env

    async def _terminate_process(self, process: asyncio.subprocess.Process):
        if process.returncode is not None:
            return
        try:
            process.terminate()
            await asyncio.wait_for(process.wait(), timeout=5)
        except Exception:
            with suppress(Exception):
                process.kill()
            with suppress(Exception):
                await asyncio.wait_for(process.wait(), timeout=5)

    async def _connect_with_retry(self, server_id: str, connect_func, max_retries: int, timeout: int):
        """ç»Ÿä¸€çš„è¿æ¥é‡è¯•é€»è¾‘"""
        if server_id in self.sessions:
            logger.warning(f"æœåŠ¡ç«¯ {server_id} å·²ç»è¿æ¥ï¼Œè·³è¿‡")
            return True

        for attempt in range(max_retries):
            try:
                logger.info(f"æ­£åœ¨è¿æ¥ {server_id}... ({attempt + 1}/{max_retries})")
                await connect_func()
                logger.info(f"âœ… æˆåŠŸè¿æ¥: {server_id}")
                return True
            except asyncio.TimeoutError:
                logger.error(f"âŒ {server_id} è¶…æ—¶ ({attempt + 1}/{max_retries})")
            except Exception as e:
                import traceback
                logger.error(f"âŒ {server_id} å¤±è´¥ ({attempt + 1}/{max_retries}): {e}")
                logger.error(traceback.format_exc())
            
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt
                logger.info(f"â³ {wait_time}ç§’åé‡è¯• {server_id}...")
                await asyncio.sleep(wait_time)

        logger.error(f"ğŸš« {server_id} è¿æ¥å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°")
        return False

    async def connect_to_sse_server(
        self,
        server_id: str,
        url: str,
        command: str | None,
        args: list,
        env: dict,
        cwd: str | None = None,
        timeout: int | None = None,
        max_retries: int | None = None,
    ):
        timeout = timeout or self.connection_timeout
        max_retries = max_retries or self.max_retries

        async def _connect():
            attempt_stack = AsyncExitStack()
            process = None
            try:
                # æ£€æŸ¥ç«¯ç‚¹æ˜¯å¦å·²å­˜æ´»
                should_start = command is not None
                if should_start:
                    try:
                        if await self._is_sse_endpoint_alive(url):
                            should_start = False
                    except Exception:
                        pass

                # å¯åŠ¨è¿›ç¨‹ï¼ˆå¦‚éœ€è¦ï¼‰
                if should_start:
                    process = await asyncio.create_subprocess_exec(command, *args, env=env, cwd=cwd)
                    self._server_processes[server_id] = process
                    
                    # ç­‰å¾…æœåŠ¡å¯åŠ¨
                    start_time = time.monotonic()
                    while time.monotonic() - start_time < 10:
                        if await self._is_sse_endpoint_alive(url):
                            break
                        await asyncio.sleep(0.5)
                    else:
                         logger.warning(f"âš ï¸ æœåŠ¡ç«¯ {server_id} å¯åŠ¨è¾ƒæ…¢ï¼Œå°è¯•ç›´æ¥è¿æ¥...")

                # å»ºç«‹è¿æ¥
                transport = await attempt_stack.enter_async_context(
                    sse_client(url, timeout=5, sse_read_timeout=600)
                )
                read_stream, write_stream = transport
                session = await attempt_stack.enter_async_context(ClientSession(read_stream, write_stream))
                await asyncio.wait_for(session.initialize(), timeout=timeout)

                self._server_exit_stacks[server_id] = attempt_stack
                self.sessions[server_id] = {"session": session}
            except Exception:
                with suppress(Exception):
                    await attempt_stack.aclose()
                if process:
                    with suppress(Exception):
                        await self._terminate_process(process)
                    self._server_processes.pop(server_id, None)
                raise

        return await self._connect_with_retry(server_id, _connect, max_retries, timeout)

    async def connect_to_local_server(
        self,
        server_id: str,
        command: str,
        args: list,
        env: dict,
        cwd: str | None = None,
        timeout: int | None = None,
        max_retries: int | None = None,
    ):
        timeout = timeout or self.connection_timeout
        max_retries = max_retries or self.max_retries

        async def _connect():
            server_params = StdioServerParameters(
                command=command, 
                args=args, 
                env=env,
                cwd=cwd,
                encoding_error_handler="ignore"
            )
            attempt_stack = AsyncExitStack()
            try:
                stdio_transport = await attempt_stack.enter_async_context(stdio_client(server_params))
                stdio, write = stdio_transport
                session = await attempt_stack.enter_async_context(ClientSession(stdio, write))
                await asyncio.wait_for(session.initialize(), timeout=timeout)
                
                self._server_exit_stacks[server_id] = attempt_stack
                self.sessions[server_id] = {"session": session}
            except Exception:
                with suppress(Exception):
                    await attempt_stack.aclose()
                raise

        return await self._connect_with_retry(server_id, _connect, max_retries, timeout)

    
    async def list_tools(self):
        """åˆ—å‡ºæ‰€æœ‰æœåŠ¡ç«¯çš„å·¥å…·å¹¶å°†è¯¦ç»†ä¿¡æ¯å­˜å‚¨èµ·æ¥ï¼ˆå®¹é”™å¤„ç†ï¼‰"""
        if not self.sessions:
            logger.error("æ²¡æœ‰å·²è¿æ¥çš„æœåŠ¡ç«¯")
            return

        logger.info("åŠ è½½æœåŠ¡ç«¯å·¥å…·:")
        self.tools_map.clear()
        
        successful_loads = 0
        total_sessions = len(self.sessions)
        
        for server_id, session_info in self.sessions.items():
            session = session_info["session"]
            try:
                # æ·»åŠ è¶…æ—¶æ§åˆ¶åˆ°å·¥å…·åˆ—è¡¨è·å–
                response = await asyncio.wait_for(session.list_tools(), timeout=20)
                
                tool_count = len(response.tools)
                for tool in response.tools:
                    self.tools_map[tool.name] = {
                        "server_id": server_id,
                        "description": tool.description,
                        "input_schema": tool.inputSchema
                    }
                    logger.info(f"  ğŸ“§ å·¥å…·: {tool.name}, æ¥æº: {server_id}")
                
                logger.info(f"âœ… æœåŠ¡ç«¯ {server_id}: åŠ è½½äº† {tool_count} ä¸ªå·¥å…·")
                successful_loads += 1
                
            except asyncio.TimeoutError:
                logger.error(f"âŒ ä»æœåŠ¡ç«¯ {server_id} è·å–å·¥å…·åˆ—è¡¨è¶…æ—¶")
            except Exception as e:
                logger.error(f"âŒ ä»æœåŠ¡ç«¯ {server_id} è·å–å·¥å…·åˆ—è¡¨æ—¶å‡ºé”™: {e}")
        
        total_tools = len(self.tools_map)
        logger.info(f"ğŸ“Š å·¥å…·åŠ è½½ç»“æœ: {successful_loads}/{total_sessions} ä¸ªæœåŠ¡ï¼Œå…± {total_tools} ä¸ªå·¥å…·å¯ç”¨")
    
    async def _build_tool_list(self):
        """æ ¹æ®å­˜å‚¨çš„å·¥å…·ä¿¡æ¯æ„å»ºç»Ÿä¸€çš„å·¥å…·åˆ—è¡¨"""
        available_tools = []
        for tool_name, tool_info in self.tools_map.items():
            available_tools.append({
                "type": "function",
                "function": {
                    "name": tool_name,
                    "description": tool_info["description"],
                    "parameters": tool_info["input_schema"] 
                }
            })
        return available_tools
    
    def _append_assistant_tool_calls(self, tool_calls: list[dict], history: list = None):
        target_history = history if history is not None else self.conversation_history
        target_history.append(
            {
                "role": "assistant",
                "tool_calls": [
                    {
                        "id": tc["id"],
                        "type": "function",
                        "function": {"name": tc["name"], "arguments": tc["arguments"]},
                    }
                    for tc in tool_calls
                ],
            }
        )

    async def _execute_agent_loop(self, messages: list, tools: list) -> str:
        """é€šç”¨ Agent æ‰§è¡Œå¾ªç¯"""
        tool_cycle_count = 0
        while True:
            # print(f"DEBUG: Sending messages to LLM: {json.dumps(messages, ensure_ascii=False, indent=2)}")
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                stream=True,
                max_tokens=8192,
                temperature=0.7,
                tools=tools if tools else None, # å¦‚æœæ²¡æœ‰å·¥å…·ï¼Œä¸ä¼  tools å‚æ•°
            )

            final_content = ""
            has_tool_calls = False
            is_intercepted_json = False
            tool_calls = []
            json_buffer = ""

            for chunk in response:
                if chunk.choices and chunk.choices[0].delta:
                    delta = chunk.choices[0].delta
                    try:
                        if delta.reasoning_content:
                            print("\033[92m" + delta.reasoning_content + "\033[0m", end="", flush=True)
                    except:
                        pass
                    if delta.content:
                        content = delta.content
                        print(content, end="", flush=True)
                        final_content += content
                        json_buffer += content
                    if delta.tool_calls:
                        has_tool_calls = True
                        for tc in delta.tool_calls:
                            existing = next((x for x in tool_calls if x.index == tc.index), None)
                            if existing:
                                existing.function.arguments += tc.function.arguments
                                if tc.function.name:
                                    existing.function.name = (existing.function.name or "") + tc.function.name
                            else:
                                tool_calls.append(tc)

            if not has_tool_calls:
                extracted = self._extract_text_tool_calls(json_buffer)
                if extracted:
                    logger.info(f"æ£€æµ‹åˆ° {len(extracted)} ä¸ªçº¯æ–‡æœ¬ JSON å·¥å…·è°ƒç”¨")
                    tool_calls = extracted
                    has_tool_calls = True
                    is_intercepted_json = True

            if has_tool_calls:
                tool_cycle_count += 1
                if tool_cycle_count > 10:
                    return "ç³»ç»Ÿæ£€æµ‹åˆ°å¾ªç¯è°ƒç”¨ï¼Œå·²åœæ­¢æ‰§è¡Œã€‚"

                tool_results = await self._process_tool_calls(tool_calls)
                
                # ç»Ÿä¸€è½¬æ¢ tool_calls ä¸º dict æ ¼å¼
                tool_calls_dicts = []
                for tc in tool_calls:
                    if isinstance(tc, dict):
                        tool_calls_dicts.append(tc)
                    else:
                        tool_calls_dicts.append({
                            "id": tc.id,
                            "name": tc.function.name,
                            "arguments": tc.function.arguments
                        })
                
                self._append_assistant_tool_calls(tool_calls_dicts, history=messages)
                messages.extend(tool_results)
                
                # Check for errors loop
                all_errors = True
                for result in tool_results:
                     if not result["content"].startswith("Error:"):
                         all_errors = False
                         break
                
                if all_errors:
                     return "å·¥å…·è°ƒç”¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥å‚æ•°æˆ–é‡è¯•ã€‚"
                continue
            else:
                print()
                messages.append({"role": "assistant", "content": final_content})
                return final_content

    async def _run_perception_phase(self, query: str):
        print(f"\nğŸ“¡ [Phase 1] æ„ŸçŸ¥å±‚å¯åŠ¨...")
        # å·¥å…·åç§°å¯èƒ½å¸¦æˆ–ä¸å¸¦å‰ç¼€ï¼Œæ ¹æ®å®é™…åŠ è½½æƒ…å†µåŒ¹é…
        # è¿™é‡Œæˆ‘ä»¬æ”¾å®½åŒ¹é…æ¡ä»¶ï¼Œåªè¦åŒ…å« 'get_irrigation_status' æˆ– 'get_forecast_week' å³å¯
        target_tools = ['get_irrigation_status', 'get_forecast_week']
        tools = []
        
        all_tools = await self._build_tool_list()
        for t in all_tools:
            name = t['function']['name']
            # æ£€æŸ¥åç§°æ˜¯å¦å®Œå…¨åŒ¹é…æˆ–ä½œä¸ºåç¼€åŒ¹é…ï¼ˆä¾‹å¦‚ weather.get_forecast_weekï¼‰
            if any(name == target or name.endswith(f".{target}") for target in target_tools):
                tools.append(t)
                
        messages = [
            {"role": "system", "content": PERCEPTION_PROMPT},
            {"role": "user", "content": f"ä»»åŠ¡ï¼šè·å–å½“å‰ç¯å¢ƒçŠ¶æ€ã€‚ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼š{query}"}
        ]
        return await self._execute_agent_loop(messages, tools)

    async def _run_reasoning_phase(self, query: str, perception_data: str):
        print(f"\nğŸ§  [Phase 2] å†³ç­–å±‚å¯åŠ¨...")
        # å¯ç”¨ search å·¥å…·
        target_tools = ['search']
        tools = []
        
        all_tools = await self._build_tool_list()
        for t in all_tools:
            name = t['function']['name']
            if any(name == target or name.endswith(f".{target}") for target in target_tools):
                tools.append(t)

        messages = [
            {"role": "system", "content": REASONING_PROMPT},
            {"role": "user", "content": f"æ„ŸçŸ¥æ•°æ®ï¼š\n{perception_data}\n\nç”¨æˆ·è¯·æ±‚ï¼š{query}"}
        ]
        return await self._execute_agent_loop(messages, tools)

    async def _run_action_phase(self, decision_json: dict):
        print(f"\nğŸšœ [Phase 3] æ‰§è¡Œå±‚å¯åŠ¨...")
        tools = [t for t in await self._build_tool_list() if t['function']['name'] in ['start_irrigation']]
        messages = [
            {"role": "system", "content": ACTION_PROMPT},
            {"role": "user", "content": f"å·²ç¡®è®¤å†³ç­–ï¼š\n{json.dumps(decision_json, ensure_ascii=False)}\n\nç”¨æˆ·å·²ç¡®è®¤æ‰§è¡Œã€‚è¯·ä¸‹å‘æŒ‡ä»¤ã€‚"}
        ]
        return await self._execute_agent_loop(messages, tools)

    def _extract_json_from_response(self, text: str) -> dict | None:
        """ä»å“åº”æ–‡æœ¬ä¸­æå– JSON å¯¹è±¡"""
        text = text.strip()
        
        # 1. å°è¯•æå– markdown ä»£ç å—ï¼ˆå¤„ç†å¤šä¸ªå—çš„æƒ…å†µï¼‰
        code_blocks = re.findall(r"```(?:json)?\s*([\s\S]*?)\s*```", text)
        for block in code_blocks:
            try:
                # å°è¯•è§£ææ¯ä¸ªä»£ç å—ï¼Œçœ‹æ˜¯å¦åŒ…å«å†³ç­–ç»“æ„
                data = json.loads(block.strip())
                if isinstance(data, dict) and ("decision" in data or "decision_reasoning" in data):
                    return data
            except json.JSONDecodeError:
                continue

        # 2. å°è¯•ç›´æ¥è§£æ
        with suppress(json.JSONDecodeError):
            return json.loads(text)

        # 3. å°è¯•æŸ¥æ‰¾æœ€å¤–å±‚çš„ {}
        try:
            start = text.find("{")
            end = text.rfind("}") + 1
            if start >= 0 and end > start:
                return json.loads(text[start:end])
        except json.JSONDecodeError:
            pass
            
        return None

    async def process_query(self, query: str) -> str:
        # 0. çŠ¶æ€æ£€æŸ¥ï¼šæ˜¯å¦åœ¨ç­‰å¾…ç¡®è®¤
        if self.pending_decision:
            if query.lower() in ['y', 'yes', 'æ˜¯', 'ç¡®è®¤', 'ok', 'å¥½çš„']:
                result = await self._run_action_phase(self.pending_decision)
                self.pending_decision = None
                return result
            else:
                self.pending_decision = None
                return "âŒ ç”¨æˆ·å·²å–æ¶ˆçŒæº‰æ“ä½œã€‚"

        # 1. æ„ŸçŸ¥é˜¶æ®µ
        perception_output = await self._run_perception_phase(query)
        # ç®€å•éªŒè¯è¾“å‡ºæ˜¯å¦çœ‹èµ·æ¥åƒ JSON
        if not perception_output.strip().startswith("{"):
             logger.warning(f"æ„ŸçŸ¥å±‚è¾“å‡ºæ ¼å¼å¯èƒ½ä¸æ­£ç¡®: {perception_output[:50]}...")

        # 2. å†³ç­–é˜¶æ®µ
        reasoning_output = await self._run_reasoning_phase(query, perception_output)
        
        # 3. è§£æå†³ç­–å¹¶å¤„ç†
        try:
            decision_json = self._extract_json_from_response(reasoning_output)
            
            if decision_json:
                # æå–è‡ªç„¶è¯­è¨€æ€»ç»“ï¼ˆJSON ä¹‹å‰çš„éƒ¨åˆ†ï¼‰
                summary = reasoning_output[:reasoning_output.find("{")].strip()
                if summary:
                    print(f"\n{summary}\n")
                
                decision_core = decision_json.get("decision", {})
                reasoning_core = decision_json.get("decision_reasoning", {})

                if decision_core.get("irrigate") is True:
                    self.pending_decision = decision_core
                    
                    # æ„é€ ç¡®è®¤è¯·æ±‚
                    confirm_msg = (
                        f"\n{'='*60}\n"
                        f"ğŸŒ¾ **æ™ºèƒ½çŒæº‰å†³ç­–æŠ¥å‘Š**\n"
                        f"{'='*60}\n\n"
                        f"ğŸ“Š **å½“å‰çŠ¶æ€åˆ†æ**\n"
                        f"   ğŸ’§ æ°´åˆ†èƒè¿«è¯„ä¼°: {reasoning_core.get('water_stress_assessment', 'N/A')}\n"
                        f"   ğŸŒ¤ï¸  æ°”è±¡å½±å“åˆ†æ: {reasoning_core.get('weather_impact_analysis', 'N/A')}\n"
                        f"   ğŸŒ± ä½œç‰©éœ€æ°´åˆ†æ: {reasoning_core.get('crop_demand_analysis', 'N/A')}\n\n"
                        f"ğŸ’¡ **å†³ç­–å»ºè®®**\n"
                        f"   âœ… å»ºè®®æ‰§è¡ŒçŒæº‰\n"
                        f"   ğŸ’§ å»ºè®®çŒæº‰é‡: {decision_core.get('irrigation_amount_mm', 0)} mm\n"
                        f"   â±ï¸ å»ºè®®æ—¶é•¿: {decision_core.get('irrigation_duration_min', 0)} åˆ†é’Ÿ\n"
                        f"   ğŸ•’ æ‰§è¡Œæ—¶æœº: {decision_core.get('irrigation_time_window', 'ç«‹å³')}\n"
                        f"   ğŸ“ˆ å†³ç­–ç½®ä¿¡åº¦: {decision_json.get('confidence_score', 0)*100:.0f}%\n\n"
                        f"ğŸ“ **èŠ‚æ°´ç­–ç•¥**\n"
                        f"   {reasoning_core.get('water_saving_strategy', 'N/A')}\n"
                        f"\n{'='*60}\n"
                        f"â“ **æ˜¯å¦ç«‹å³æ‰§è¡ŒçŒæº‰ï¼Ÿ**\n"
                        f"   è¾“å…¥ 'y' æˆ– 'æ˜¯' ç¡®è®¤æ‰§è¡Œ\n"
                        f"   è¾“å…¥å…¶ä»–å†…å®¹å–æ¶ˆæ“ä½œ\n"
                        f"{'='*60}\n"
                    )
                    return confirm_msg
                else:
                    result = (
                        f"\n{'='*60}\n"
                        f"ğŸŒ¾ **æ™ºèƒ½çŒæº‰å†³ç­–æŠ¥å‘Š**\n"
                        f"{'='*60}\n\n"
                        f"ğŸ“Š **å½“å‰çŠ¶æ€åˆ†æ**\n"
                        f"   ğŸ’§ æ°´åˆ†èƒè¿«è¯„ä¼°: {reasoning_core.get('water_stress_assessment', 'N/A')}\n"
                        f"   ğŸŒ¤ï¸  æ°”è±¡å½±å“åˆ†æ: {reasoning_core.get('weather_impact_analysis', 'N/A')}\n\n"
                        f"ğŸ’¡ **å†³ç­–å»ºè®®**\n"
                        f"   âœ… æ— éœ€çŒæº‰\n"
                        f"   ğŸ“ˆ å†³ç­–ç½®ä¿¡åº¦: {decision_json.get('confidence_score', 0)*100:.0f}%\n\n"
                        f"ğŸ“ **å†³ç­–ä¾æ®**\n"
                        f"   {reasoning_core.get('water_saving_strategy', 'N/A')}\n"
                        f"\n{'='*60}\n"
                    )
                    return result
            else:
                return f"âš ï¸ å†³ç­–å±‚è¿”å›äº†éæ ‡å‡†æ ¼å¼ï¼Œè¯·äººå·¥æ£€æŸ¥ï¼š\n{reasoning_output}"
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"âŒ ç³»ç»Ÿé”™è¯¯ï¼šæ— æ³•è§£æå†³ç­–ç»“æœ\né”™è¯¯: {str(e)}\nåŸå§‹è¾“å‡ºï¼š{reasoning_output}\n\nè°ƒè¯•ä¿¡æ¯:\n{error_detail}"




    async def _process_tool_calls(self, tool_calls) -> list:
        """å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆéæµå¼ï¼Œå¸¦è¶…æ—¶æ§åˆ¶ï¼‰"""
        tool_results = []
        for tool_call in tool_calls:
            tool_call_id, tool_name, tool_args_str = self._normalize_tool_call(tool_call)

            try:
                tool_args = json.loads(tool_args_str)
            except json.JSONDecodeError:
                logger.error(f"æ— æ³•è§£æå·¥å…·å‚æ•° JSON: {tool_args_str}")
                tool_results.append({
                    "role": "tool",
                    "content": f"Error: Invalid JSON arguments received: {tool_args_str}",
                    "tool_call_id": tool_call_id,
                })
                continue

            tool_info = self.tools_map.get(tool_name)
            if not tool_info:
                error_message = f"é”™è¯¯ï¼šæœªæ‰¾åˆ°å·¥å…· {tool_name} çš„é…ç½®ä¿¡æ¯ã€‚"
                logger.error(error_message)
                tool_results.append({
                    "role": "tool",
                    "content": error_message,
                    "tool_call_id": tool_call_id,
                })
                continue

            server_id = tool_info["server_id"]
            session = self.sessions[server_id]["session"]
            
            try:
                logger.info(f"ğŸ”§ è°ƒç”¨å·¥å…· {tool_name} (æœåŠ¡: {server_id}, å‚æ•°: {tool_args})")
                
                # æ·»åŠ å·¥å…·è°ƒç”¨è¶…æ—¶æ§åˆ¶
                result = await asyncio.wait_for(session.call_tool(tool_name, tool_args), timeout=self.tool_timeout)
                
                result_content = result.content[0].text
                if tool_name == "browser-use":
                    # result_content = await self._maybe_wait_browser_use_result(session, result_content)
                    pass
                logger.info(f"âœ… å·¥å…· {tool_name} æ‰§è¡ŒæˆåŠŸ")

                tool_results.append({
                    "role": "tool",
                    "content": result_content,
                    "tool_call_id": tool_call_id,
                })
                
            except asyncio.TimeoutError:
                error_message = f"å·¥å…· {tool_name} è°ƒç”¨è¶…æ—¶ ({self.tool_timeout}ç§’)"
                logger.error(f"âŒ {error_message}")
                tool_results.append({
                    "role": "tool",
                    "content": f"Error: {error_message}",
                    "tool_call_id": tool_call_id,
                })
            except Exception as e:
                error_message = f"è°ƒç”¨å·¥å…· {tool_name} æ—¶å‡ºé”™: {str(e)}"
                logger.error(f"âŒ {error_message}")
                tool_results.append({
                    "role": "tool",
                    "content": f"Error: {error_message}",
                    "tool_call_id": tool_call_id,
                })
        
        return tool_results

    def _normalize_tool_call(self, tool_call):
        if isinstance(tool_call, dict):
            return tool_call["id"], tool_call["name"], tool_call["arguments"]
        return tool_call.id, tool_call.function.name, tool_call.function.arguments


    def _extract_text_tool_calls(self, text: str) -> list[dict]:
        buf = (text or "").strip()
        if not buf:
            return []
        if "arguments" not in buf:
            return []

        candidates: list[dict] = []

        code_blocks = re.findall(r"```(?:json)?\s*([\s\S]*?)\s*```", buf)
        for block in code_blocks:
            block = block.strip()
            if not block:
                continue
            candidates.extend(self._extract_text_tool_calls(block))

        for line in buf.splitlines():
            line = line.strip()
            if not line or line.startswith("```"):
                continue
            try:
                obj = json.loads(line)
                if isinstance(obj, dict) and "name" in obj and "arguments" in obj:
                    candidates.append(obj)
            except Exception:
                pass

        if not candidates:
            cleaned = buf.replace("```json", "").replace("```", "").strip()
            try:
                obj = json.loads(cleaned)
                if isinstance(obj, dict) and "name" in obj and "arguments" in obj:
                    candidates.append(obj)
            except Exception:
                pass

        result: list[dict] = []
        for obj in candidates:
            name = obj.get("name")
            arguments = obj.get("arguments", {})
            if not name:
                continue
            args_str = json.dumps(arguments, ensure_ascii=False) if isinstance(arguments, (dict, list)) else str(arguments)
            result.append({"id": f"call_{uuid.uuid4()}", "name": str(name), "arguments": args_str})

        return result


    async def _is_sse_endpoint_alive(self, url: str) -> bool:
        parsed = urlparse(url)
        if (parsed.scheme or "http").lower() not in {"http", "https"}:
            return False

        host = parsed.hostname or "localhost"
        port = parsed.port or (443 if (parsed.scheme or "http").lower() == "https" else 80)
        path = parsed.path or "/"
        if parsed.query:
            path = f"{path}?{parsed.query}"

        try:
            reader, writer = await asyncio.wait_for(asyncio.open_connection(host, port), timeout=0.5)
        except Exception:
            return False

        try:
            request = (
                f"GET {path} HTTP/1.1\r\n"
                f"Host: {host}\r\n"
                "Accept: text/event-stream\r\n"
                "Connection: close\r\n"
                "\r\n"
            )
            writer.write(request.encode("utf-8"))
            await writer.drain()

            status_line = await asyncio.wait_for(reader.readline(), timeout=0.5)
            return b" 200 " in status_line or status_line.startswith(b"HTTP/1.1 200")
        except Exception:
            return False
        finally:
            writer.close()
            with suppress(Exception):
                await writer.wait_closed()


    async def _maybe_wait_browser_use_result(self, session: ClientSession, result_content: str) -> str:
        try:
            data = json.loads(result_content)
        except Exception:
            return result_content

        task_id = data.get("task_id")
        status = data.get("status")
        if not task_id or status not in {"pending", "running"}:
            return result_content

        deadline = time.monotonic() + self.tool_timeout
        latest = data

        while time.monotonic() + 5 <= deadline:
            await asyncio.sleep(5)
            try:
                res = await asyncio.wait_for(
                    session.call_tool("browser_get_result", {"task_id": task_id}),
                    timeout=max(1, int(deadline - time.monotonic())),
                )
                txt = res.content[0].text
                latest = json.loads(txt)
                if latest.get("status") in {"completed", "failed"}:
                    break
            except Exception:
                break

        # å°è¯•æå–å¯¹å¤§æ¨¡å‹æ›´å‹å¥½çš„æ–‡æœ¬ç»“æœ
        if latest.get("status") == "completed":
            result_data = latest.get("result", {})
            # ä¼˜å…ˆä½¿ç”¨ final_result (ç”± Agent æ€»ç»“è¿‡çš„)
            final_text = result_data.get("final_result", "")
            if final_text:
                return f"[Browser Result]\n{final_text}"
            
            # å…¶æ¬¡ä½¿ç”¨ extracted_content
            extracted = result_data.get("extracted_content", "")
            if extracted:
                 return f"[Browser Result (Raw Content)]\n{extracted}"
        
        if latest.get("status") == "failed":
            return f"[Browser Task Failed]\nError: {latest.get('error', 'Unknown error')}"

        try:
            return json.dumps(latest, ensure_ascii=False, indent=2)
        except Exception:
            return result_content


    async def chat_loop(self):
        """è¿è¡Œäº¤äº’å¼èŠå¤©å¾ªç¯"""
        print("\n" + "="*60)
        print("ğŸŒ¾ æ™ºèƒ½å†œä¸šå†³ç­–åŠ©æ‰‹å·²å¯åŠ¨ï¼")
        print("="*60)
        print("ğŸ’¡ æç¤ºï¼š")
        print("  - è¾“å…¥ 'exit' é€€å‡ºç¨‹åº")
        print("  - è¾“å…¥ 'clear' æ¸…ç©ºå¯¹è¯å†å²")
        print("="*60 + "\n")

        while True:
            try:
                # ä½¿ç”¨æ›´æ˜æ˜¾çš„æç¤ºç¬¦
                print("\n" + "-"*60)
                query = input("ğŸ¤” æ‚¨çš„é—®é¢˜: ").strip()
                print("-"*60 + "\n")
                
                if query.lower() == 'exit':
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                if query.lower() == 'clear':
                    self.conversation_history = [] # æ¸…ç©ºå†å²
                    print("âœ… å¯¹è¯å†å²å·²æ¸…ç©ºã€‚\n")
                    continue
                
                if not query:
                    print("âš ï¸  è¯·è¾“å…¥é—®é¢˜\n")
                    continue

                response = await self.process_query(query)
                # logger.info(f"AIå›å¤: {response}")

            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...")
                break
            except Exception as e:
                logger.error(f"å‘ç”Ÿé”™è¯¯: {str(e)}") # æ”¹ä¸º error çº§åˆ«æ—¥å¿—

    async def clean(self):
        """æ¸…ç†æ‰€æœ‰èµ„æº"""
        for server_id, stack in list(self._server_exit_stacks.items()):
            try:
                await stack.aclose()
            except Exception as e:
                msg = str(e)
                if "cancel scope" in msg:
                    logger.warning(f"æ¸…ç†æœåŠ¡ç«¯ {server_id} èµ„æºæ—¶å‘ç”Ÿå¼‚å¸¸ï¼ˆå·²å¿½ç•¥ï¼‰: {msg}")
                else:
                    logger.error(f"æ¸…ç†æœåŠ¡ç«¯ {server_id} èµ„æºæ—¶å‘ç”Ÿé”™è¯¯: {msg}")

        for server_id, process in list(self._server_processes.items()):
            with suppress(Exception):
                await self._terminate_process(process)

        self._server_exit_stacks.clear()
        self._server_processes.clear()
        self.sessions.clear()
        self.tools_map.clear()
        self.conversation_history.clear()
        logger.info("[CLEAN] å·²æ¸…ç†æ‰€æœ‰èµ„æº")


async def main():
    # å¯åŠ¨å¹¶åˆå§‹åŒ– MCP å®¢æˆ·ç«¯
    client = MCPClient()
    try:
        # ä»é…ç½®æ–‡ä»¶åŠ è½½ MCP æœåŠ¡
        await client.load_servers_from_config("mcp_servers.json")
        # åˆ—å‡º MCP æœåŠ¡å™¨ä¸Šçš„å·¥å…·
        await client.list_tools()
        # è¿è¡Œäº¤äº’å¼èŠå¤©å¾ªç¯ï¼Œå¤„ç†ç”¨æˆ·å¯¹è¯
        await client.chat_loop()
    finally:
        # æ¸…ç†èµ„æº
        await client.clean()


if __name__ == "__main__":
    asyncio.run(main())
